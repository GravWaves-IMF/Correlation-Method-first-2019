{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Creating the Correlation vs GPS Time Dataframe\n",
    "\n",
    "**Paolo Marcoccia<sup>1</sup>, Felicia Frederiksson<sup>2</sup>, Alex B. Nielsen<sup>1</sup> and Germano Nardini<sup>1</sup>**\n",
    "\n",
    "<sub>1. University of Stavanger, Institutt for Matematikk og Fysikk, Kjølv Egelands hus, 5.etg, E-blokk, 4021 Stavanger, Norway </sub> <br>\n",
    "<sub>2. University of Uppsala, Department of Physics and Astronomy,Ångströmlaboratoriet, Lägerhyddsvägen 1, 751 20 Uppsala, Sweden</sub> \n",
    "\n",
    "We encourage use of these data in derivative works. If you use the material provided here, please cite [our paper.]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to generate the [CorrVsTime.csv](https://github.com/GravWaves-IMF/Correlation-Method-first-2019-/blob/master/Code/GW151012Final/GW151012data.py) dataframe containing the Correlation vs GPS Time for the analyzed events.\n",
    "The pipeline, in particular, will be run for the event _GW151012_ but it may easily be applied to all the other events.\n",
    "In order to run this pipeline, however, you need the _residuals.hdf_ file generated by running the [CreateResiduals.ipynb](https://github.com/gwastro/gw150914_investigation/blob/master/CreateResiduals.ipynb) notebook.\n",
    "Let's start my moving into the directory of the event we wish to analyze :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuza91/Documents/IPyNB/GWO1/GW170104\n"
     ]
    }
   ],
   "source": [
    "cd GW170104/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each event directory, there will be a [init_module.py](https://github.com/GravWaves-IMF/Correlation-Method-first-2019-/blob/master/Code/init_module.py) and a [GW*event_name*.py](https://github.com/GravWaves-IMF/Correlation-Method-first-2019-/blob/master/Code/GW151012Final/GW151012data.py), the first one once launched will automatically load all the modules needed to run the pipeline, the latter instead will set some local variables around the choosed event.\n",
    "Let's launch them both :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment length: 16.0\n"
     ]
    }
   ],
   "source": [
    "%run init_module.py\n",
    "#%run GW150914data.py\n",
    "#%run GW151012data.py\n",
    "#%run GW151226data.py\n",
    "%run GW170104data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inizialize some void dictionary :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, psd_data, ts, ts3, waveforms, psds = {},{},{},{},{},{}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze the correlations between the two detectors in a _200 ms_ time interval centered around the _LIGO_ claimed coalescence time.\n",
    "Furthermore, we will estimate the correlations each _0.1 ms_, hence we will estimate _2000_ correlations in total during the following pipeline.\n",
    "Let's generate some auxiliary vectors in order to do so :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rangenum = range(2000)\n",
    "timespan = np.linspace(0.,0.2,2000)\n",
    "void = np.zeros(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to load both the Strain Data of the detectors at the time of event and the Residual data obtained by running the [CreateResiduals.ipynb](https://github.com/gwastro/gw150914_investigation/blob/master/CreateResiduals.ipynb) notebook.\n",
    "The Strain Data of the events may be downloaded at the [GWOSC](https://www.gw-openscience.org/catalog/GWTC-1-confident/) website, however depending on how old your strain data is, it may be saved with both the header name _LOSC_ or _GWOSC_.\n",
    "In our case, the data of _GW150914_ was saved with the _LOSC_ header name, while the data of the other events was saved with the _GWOSC_ header, for avoiding failing in the loading of the strain data, one should check carefully and change the <em>hd_nm</em> variable in the [GW*event_name*.py](https://github.com/GravWaves-IMF/Correlation-Method-first-2019-/blob/master/Code/GW151012Final/GW151012data.py) script according to the data.\n",
    "Furthermore, in the [res.py](https://github.com/GravWaves-IMF/Correlation-Method-first-2019-/blob/master/Code/res.py) file, there would be a <em>res.get_LSC_Full_strain()</em> that was built to load _LOSC_ header file, and a <em>res.get_GWSC_Full_strain()</em> that was built for _GWOSC_ header file.\n",
    "In our case, for _GW151012_ will be :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the first one for GW150914\n",
    "\n",
    "#strain = res.get_LSC_Full_strain(hd_nm,psd_start_time-pad_data, psd_end_time + pad_data)\n",
    "\n",
    "# Use the second one for the others event\n",
    "\n",
    "strain = res.get_GWSC_Full_strain(hd_nm,psd_start_time-pad_data, psd_end_time + pad_data)\n",
    "\n",
    "resstrain = res.get_Full_residual_strain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also inizialize an auxiliary dataframe, that will be used to save the correlation data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'GPSTime' : basetime + timespan, \n",
    "     'Timeshift' : timespan,\n",
    "     'SigCorr' : void,\n",
    "     'ResCorr' : void,\n",
    "     'DiffCorr' : void})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cut down the data around the event, and let's whiten that in the frequency band defined by <em>f_low</em>, <em>f_high</em>, the values of the two previous variable are stated for each event in the [GW*event_name*.py](https://github.com/GravWaves-IMF/Correlation-Method-first-2019-/blob/master/Code/GW151012Final/GW151012data.py) :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ifo in ifos :\n",
    "                             ts[ifo] = strain[ifo].time_slice((tc - 75.), (tc + 75.))\n",
    "                             ts3[ifo] = resstrain[ifo].time_slice((tc - 75.), (tc + 75.))\n",
    "\n",
    "ts = res.whiten(ts, f_low, f_high)\n",
    "ts3 = res.whiten(ts3, f_low, f_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may finally define the function that will estimate the correlation among the detectors in function of GPS time, given a certain time shift among the two detectors, we'll define that in a way that may be parallelized by using the _multiprocessing_ module :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CorrAnal(i) :\n",
    "      \n",
    "              if(i%100 == 0 or i == 1999) :\n",
    "                print (\"Percentage of completition : {}\".format((df.Timeshift[i]*100)/0.2))                \n",
    "              tau, corr = res.cross_correlation(ts['H1'], ts['L1'], (basetime + df.Timeshift[i])) \n",
    "              tau, corr_null = res.cross_correlation(ts3['H1'], ts3['L1'], (basetime + df.Timeshift[i]))\n",
    "              df.SigCorr[i], df.ResCorr[i] = res.corr_wsgn_near_ml(corr,timedl,tdlerr), res.corr_wsgn_near_ml(corr_null,timedl,tdlerr)\n",
    "              df.DiffCorr[i] = abs(df.SigCorr[i] - df.ResCorr[i])\n",
    "              if(abs(df.ResCorr[i]) > abs(df.SigCorr[i])) : df.DiffCorr[i] = - df.DiffCorr[i]\n",
    "              return [df.Timeshift[i], df.SigCorr[i], df.ResCorr[i], df.DiffCorr[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous function, will be now run over <em>6</em> cores, the reason that lead us to choose <em>6</em> cores is that this pipeline was run in a laptop having <em>4</em> physical cores virtualized to <em>8</em>.\n",
    "The number of cores used for the parallelization may still be decided in function of the machine used to run that, note though that a number too high in cores may result in slowing down due to processes queue :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of completition : 0.0\n",
      "Percentage of completition : 5.00250125063\n",
      "Percentage of completition : 10.0050025013\n",
      "Percentage of completition : 15.0075037519\n",
      "Percentage of completition : 20.0100050025\n",
      "Percentage of completition : 25.0125062531\n",
      "Percentage of completition : 30.0150075038\n",
      "Percentage of completition : 35.0175087544\n",
      "Percentage of completition : 40.020010005\n",
      "Percentage of completition : 45.0225112556\n",
      "Percentage of completition : 50.0250125063\n",
      "Percentage of completition : 55.0275137569\n",
      "Percentage of completition : 60.0300150075\n",
      "Percentage of completition : 65.0325162581\n",
      "Percentage of completition : 70.0350175088\n",
      "Percentage of completition : 75.0375187594\n",
      "Percentage of completition : 80.04002001\n",
      "Percentage of completition : 85.0425212606\n",
      "Percentage of completition : 90.0450225113\n",
      "Percentage of completition : 95.0475237619\n",
      "Percentage of completition : 100.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "         results = {}\n",
    "         p = Pool(6)\n",
    "         results = p.map(CorrAnal,rangenum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're using the _MPI_ module, the execution of the last command wouldn't be linear, that's because when using _mpi_ the steps on which the instructions need to be run, passed to the function through the _rangenum_ array, will be sliced and given to the various core.\n",
    "Hence, we now need to reorder the created Dataframe in order to save that : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in rangenum:\n",
    "         for j in rangenum:\n",
    "             if(df.Timeshift[i] == results[j][0]):\n",
    "                 df.SigCorr[i] = results[j][1]\n",
    "                 df.ResCorr[i] = results[j][2]\n",
    "                 df.DiffCorr[i] = results[j][3]\n",
    "                 break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we just need to save the created dataframe in a _.csv_ file :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('CorrVsTime.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your [CorrVsTime.csv](https://github.com/GravWaves-IMF/Correlation-Method-first-2019-/blob/master/Code/GW151012Final/GW151012data.py) dataframe is finally ready to be analyzed ! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
